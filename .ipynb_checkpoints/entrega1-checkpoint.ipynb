{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto integrador 1\n",
    "## Proyecto de analisis de imagenes\n",
    "## Integrantes:\n",
    "\n",
    "   - Juliana Ochoa Ramirez\n",
    "   - Javier Arturo Rozo Alzate\n",
    "   - Mateo Graciano\n",
    "   - Cristian David Muñoz Mora\n",
    "   - Juan Mauricio Cuscagua López\n",
    "    \n",
    "## Entendimiento del problema\n",
    "\n",
    "- **Determinar los objetivos**: Construir un aplicativo que permita reconocer si el rostro humano de una imagen se encuentra dentro de la muestra de individuos que ya se conocen. Lo anterior, se realiza a través de las características de la cara misma y que tan cercano se encuentra con una imagen del set que se conoce y así poder clasificar si pertenece o no.\n",
    "\n",
    "Identificación de caras: ¿quién soy? (test de uno a muchos)/\n",
    "verificación o autentificaci+on de caras ¿soy quien digo ser? (test de uno a uno)/ \n",
    "test de lista (¿me estás buscando?),\n",
    "\n",
    "\n",
    "- **Evaluación de la situación**: ¿cuál es el conocimiento previo disponible acerca del problema?, ¿se cuenta con la cantidad de datos requerida para resolver el problema?, ¿cuál es la relación coste beneficio de la aplicación de DM?\n",
    "\n",
    "- **Que solución pretende dar el proyecto**\n",
    "\n",
    "## Entendimiento de los datos\n",
    "\n",
    "explicar maso como es la forma en la que los vamos a almacenar y que son en escala de grises y todos eso\n",
    "\n",
    "identificar su calidad y establecer las relaciones más evidentes que permitan definir las primeras hipótesis\n",
    "\n",
    "- **Recolección de datos iniciales**: Esta tarea tiene como objetivo, elaborar informes con una lista de los datos adquiridos, su localización, las técnicas utilizadas en su recolección y los problemas y soluciones inherentes a este proceso\n",
    "\n",
    "- **Descripción de los datos**:(número de registros y campos por registro), su identificación, el significado de cada campo y la descripción del formato inicial.\n",
    "\n",
    "- **Exploración de datos**:  La salida de esta tarea es un informe de exploración de los datos, aplicación de pruebas estadísticas básicas, que revelen propiedades de los datos adquiridos.\n",
    "\n",
    "- **Verificación de la calidad de los datos**: La idea en este punto, es asegurar la completitud y corrección de los datos.\n",
    "\n",
    "## Preparacón de los datos\n",
    "Selección de datos que subconjunto de los datos vamos a dejar.\n",
    "\n",
    "- **Limpieza de los datos**:  tecnicas 'normalización de los datos, discretización de campos numéricos, tratamiento de valores ausentes, reducción del volumen de datos, etc\n",
    "\n",
    "- **Estructuración de los datos**: Esta tarea incluye las operaciones de preparación de los datos tales como la generación de nuevos atributos a partir de atributos ya existentes, integración de nuevos registros o transformación de valores para atributos existentes\n",
    "\n",
    "- **Integración de los datos**:  generación de nuevos campos a partir de otros existentes, creación de nuevos registros, fusión de tablas campos o nuevas tablas donde se resumen características de múltiples registros o de otros campos en nuevas tablas de resumen.\n",
    "\n",
    "- **Formateo de los datos**: reordenación de los campos y/o registros de la tabla o el ajuste de los valores de los campos a las limitaciones de las herramientas de modelación. Cambio de 180,200 a 10, 180.\n",
    "\n",
    "Creo que estas cosas de arriba se debenintegrar a los chunks de abajo - comparto y podemos empezar a completar con lo que hemos hecho pero debemos pensar mas en el proyecto final y en que hariamos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias usadas en el proyecto y funciones creadas utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # Lee las imagenes jpg\n",
    "import re\n",
    "import random # Crea Numeros aleatores\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=True,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = ['faces','outliers']#classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all image files\n",
    "import glob\n",
    "image_list = []\n",
    "base1='input/faces94/*'\n",
    "male=[]\n",
    "female=[]\n",
    "n_im=0\n",
    "for root1 in glob.glob(base1):\n",
    "    base2=root1+'/*'\n",
    "    for (root2) in glob.glob(base2):\n",
    "        base3=root2+'/*.jpg'\n",
    "        for (root3) in glob.glob(base3):\n",
    "            image_list.append(root3)\n",
    "            if('/male/'in root3):\n",
    "                male.append(n_im)\n",
    "            if('/female/'in root3):\n",
    "                female.append(n_im)\n",
    "            if('/malestaff/'in root3):\n",
    "                male.append(n_im)\n",
    "            n_im+=1\n",
    "\n",
    "# Make a whole matrix with all dataset 180x180*num_images\n",
    "data_set=np.zeros((len(image_list),180,180))\n",
    "for image in range(len(image_list)):\n",
    "    data_set[image,:,:]=cv2.cvtColor(cv2.resize(cv2.imread(image_list[image]),(180, 180)),cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "outlier_list = []\n",
    "base1='input/Outliers/*'\n",
    "for root1 in glob.glob(base1):\n",
    "    outlier_list.append(root1)\n",
    "    \n",
    "data_set_out=np.zeros((len(outlier_list),180,180))\n",
    "for image in range(len(outlier_list)):\n",
    "    data_set_out[image,:,:]=cv2.cvtColor(cv2.resize(cv2.imread(outlier_list[image]),(180, 180)),cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "axs[0].imshow(data_set[2500,:,:], cmap = plt.cm.gray) #check\n",
    "axs[0].set_title('Imagen cualquiera')\n",
    "#plt.show()\n",
    "\n",
    "mean_face=np.mean(data_set, axis=0)\n",
    "axs[1].imshow(mean_face ,cmap = plt.cm.gray) #check\n",
    "axs[1].set_title('Imagen media: El 0')\n",
    "\n",
    "median_face=np.median(data_set, axis=0)\n",
    "axs[2].imshow(median_face ,cmap = plt.cm.gray) #check\n",
    "axs[2].set_title('Imagen mediana: El 0')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_set_aum=np.append(data_set,data_set_out,axis=0)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "axs[0].imshow(data_set_aum[-1,:,:], cmap = plt.cm.gray) #check\n",
    "axs[0].set_title('Imagen cualquiera')\n",
    "#plt.show()\n",
    "\n",
    "mean_face=np.mean(data_set_aum, axis=0)\n",
    "axs[1].imshow(mean_face ,cmap = plt.cm.gray) #check\n",
    "axs[1].set_title('Imagen media: El 0')\n",
    "\n",
    "median_face=np.median(data_set_aum, axis=0)\n",
    "axs[2].imshow(median_face ,cmap = plt.cm.gray) #check\n",
    "axs[2].set_title('Imagen mediana: El 0')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancias sobre imagenes\n",
    "## Metrica Euclidiana\n",
    "### Distribución de las normas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cero=np.mean(data_set, axis=0)\n",
    "distances=np.linalg.norm(data_set-cero, ord=None, axis=(1,2), keepdims=False)\n",
    "\n",
    "sns.distplot(distances)\n",
    "plt.title('Distribución de distancias')\n",
    "plt.show()\n",
    "\n",
    "orden=np.argsort(np.array(distances))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "axs[0].imshow(data_set[orden[0],:,:], cmap = plt.cm.gray) #check\n",
    "axs[0].set_title('Imagen más normal')\n",
    "#plt.show()\n",
    "\n",
    "axs[1].imshow(data_set[orden[-1],:,:], cmap = plt.cm.gray) #check\n",
    "axs[1].set_title('Imagen más extraña')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se identifican los outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distances_out=np.linalg.norm(data_set_out-cero, ord=None, axis=(1,2), keepdims=False)\n",
    "\n",
    "sns.distplot(distances)\n",
    "sns.rugplot(distances_out,color=\"r\")\n",
    "plt.title('Distribución de distancias')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se identifican los outliers si los incluimos en desde el comiezo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cero=np.mean(data_set_aum, axis=0)\n",
    "distances=np.linalg.norm(data_set_aum-cero, ord=None, axis=(1,2), keepdims=False)\n",
    "\n",
    "sns.distplot(distances)\n",
    "plt.title('Distribución de distancias')\n",
    "plt.show()\n",
    "\n",
    "orden=np.argsort(np.array(distances))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "axs[0].imshow(data_set_aum[orden[0],:,:], cmap = plt.cm.gray) #check\n",
    "axs[0].set_title('Imagen más normal')\n",
    "#plt.show()\n",
    "\n",
    "axs[1].imshow(data_set_aum[orden[-1],:,:], cmap = plt.cm.gray) #check\n",
    "axs[1].set_title('Imagen más extraña')\n",
    "plt.show()\n",
    "\n",
    "pred_outliers=orden[data_set.shape[0]:]\n",
    "\n",
    "real_faces=np.repeat(0,data_set.shape[0])\n",
    "real_out=np.repeat(1,data_set_out.shape[0])\n",
    "real=np.append(real_faces,real_out)\n",
    "pred=np.repeat(0,data_set_aum.shape[0])\n",
    "pred[pred_outliers]=1\n",
    "plot_confusion_matrix(real,pred, classes=['faces','outliers'],\n",
    "                      title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrica de Manhattan\n",
    "\n",
    "### Distribución de las normas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cero=np.mean(data_set, axis=0)\n",
    "distances=np.linalg.norm(data_set-cero, ord=1, axis=(1,2), keepdims=False)\n",
    "\n",
    "sns.distplot(distances)\n",
    "plt.title('Distribución de distancias')\n",
    "plt.show()\n",
    "\n",
    "orden=np.argsort(np.array(distances))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "axs[0].imshow(data_set[orden[0],:,:], cmap = plt.cm.gray) #check\n",
    "axs[0].set_title('Imagen más normal')\n",
    "#plt.show()\n",
    "\n",
    "axs[1].imshow(data_set[orden[-1],:,:], cmap = plt.cm.gray) #check\n",
    "axs[1].set_title('Imagen más extraña')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se identifican los outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distances_out=np.linalg.norm(data_set_out-cero, ord=1, axis=(1,2), keepdims=False)\n",
    "\n",
    "sns.distplot(distances)\n",
    "sns.rugplot(distances_out,color=\"r\")\n",
    "plt.title('Distribución de distancias')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se identifican los outliers si los incluimos en desde el comiezo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cero=np.mean(data_set_aum, axis=0)\n",
    "distances=np.linalg.norm(data_set_aum-cero, ord=1, axis=(1,2), keepdims=False)\n",
    "\n",
    "sns.distplot(distances)\n",
    "plt.title('Distribución de distancias')\n",
    "plt.show()\n",
    "\n",
    "orden=np.argsort(np.array(distances))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "axs[0].imshow(data_set_aum[orden[0],:,:], cmap = plt.cm.gray) #check\n",
    "axs[0].set_title('Imagen más normal')\n",
    "#plt.show()\n",
    "\n",
    "axs[1].imshow(data_set_aum[orden[-1],:,:], cmap = plt.cm.gray) #check\n",
    "axs[1].set_title('Imagen más extraña')\n",
    "plt.show()\n",
    "\n",
    "pred_outliers=orden[data_set.shape[0]:]\n",
    "\n",
    "real_faces=np.repeat(0,data_set.shape[0])\n",
    "real_out=np.repeat(1,data_set_out.shape[0])\n",
    "real=np.append(real_faces,real_out)\n",
    "pred=np.repeat(0,data_set_aum.shape[0])\n",
    "pred[pred_outliers]=1\n",
    "plot_confusion_matrix(real,pred, classes=['faces','outliers'],\n",
    "                      title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hausserdoff distance\n",
    "\n",
    "### Distribución de las normas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cero=np.mean(data_set, axis=0)\n",
    "distances=[]\n",
    "for image in range(data_set.shape[0]):\n",
    "    #print(image)\n",
    "    distances.append(directed_hausdorff(cero,data_set[image,:,:])[0])\n",
    "\n",
    "sns.distplot(distances)\n",
    "plt.title('Distribución de distancias')\n",
    "plt.show()\n",
    "\n",
    "orden=np.argsort(np.array(distances))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "axs[0].imshow(data_set[orden[0],:,:], cmap = plt.cm.gray) #check\n",
    "axs[0].set_title('Imagen más normal')\n",
    "#plt.show()\n",
    "\n",
    "axs[1].imshow(data_set[orden[-1],:,:], cmap = plt.cm.gray) #check\n",
    "axs[1].set_title('Imagen más extraña')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se identifican los outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distances_out=[]\n",
    "for image in range(data_set_out.shape[0]):\n",
    "    #print(image)\n",
    "    distances_out.append(directed_hausdorff(cero,data_set_out[image,:,:])[0])\n",
    "\n",
    "sns.distplot(distances)\n",
    "sns.rugplot(distances_out,color=\"r\")\n",
    "plt.title('Distribución de distancias')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se identifican los outliers si los incluimos en desde el comiezo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cero=np.mean(data_set_aum, axis=0)\n",
    "distances=[]\n",
    "for image in range(data_set_aum.shape[0]):\n",
    "    #print(image)\n",
    "    distances.append(directed_hausdorff(cero,data_set_aum[image,:,:])[0])\n",
    "\n",
    "sns.distplot(distances)\n",
    "plt.title('Distribución de distancias')\n",
    "plt.show()\n",
    "\n",
    "orden=np.argsort(np.array(distances))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "axs[0].imshow(data_set_aum[orden[0],:,:], cmap = plt.cm.gray) #check\n",
    "axs[0].set_title('Imagen más normal')\n",
    "#plt.show()\n",
    "\n",
    "axs[1].imshow(data_set_aum[orden[-1],:,:], cmap = plt.cm.gray) #check\n",
    "axs[1].set_title('Imagen más extraña')\n",
    "plt.show()\n",
    "\n",
    "pred_outliers=orden[data_set.shape[0]:]\n",
    "\n",
    "real_faces=np.repeat(0,data_set.shape[0])\n",
    "real_out=np.repeat(1,data_set_out.shape[0])\n",
    "real=np.append(real_faces,real_out)\n",
    "pred=np.repeat(0,data_set_aum.shape[0])\n",
    "pred[pred_outliers]=1\n",
    "plot_confusion_matrix(real,pred, classes=['faces','outliers'],\n",
    "                      title='Confusion matrix, with normalization',normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
